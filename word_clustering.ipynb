{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database.connect import getConnection\n",
    "import mysql\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "try:\n",
    "    connection = getConnection()\n",
    "except Exception:\n",
    "    print(\"✖️ Error while connecting to MySQL engine database.\")\n",
    "    print(\"ℹ️ Please make sure the environment file `.env` is located at\"+\n",
    "        \"the project root directory and contains proper configuration.\")\n",
    "    raise\n",
    "\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime W df method: 5.4 s  \n",
    "Runtime W str method: 5.7 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(\"./pre-processed/wordcounts.csv\")\n",
    "\n",
    "# check if the file exists\n",
    "my_file = file_path\n",
    "if not my_file.is_file():\n",
    "    import nltk\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "    incluided_tags = ['JJ', 'NN', 'RP', 'VB']\n",
    "    # Adjective, noun, particle, verb\n",
    "\n",
    "    word_counts = pd.DataFrame(columns=[\"word\", \"count\"])\n",
    "\n",
    "    # get the text from the database\n",
    "    cursor.execute(\"SELECT text FROM tweets WHERE text not like 'RT%' AND language = 'en'\")\n",
    "    tweets = cursor.fetchall()\n",
    "    print('got all tweets')\n",
    "\n",
    "    word_counts = {}\n",
    "    for tweet in tweets:\n",
    "        tokenized_tweet = word_tokenize(tweet[0])\n",
    "        tweet_pos = nltk.pos_tag(tokenized_tweet)\n",
    "\n",
    "        words = [word for word, pos in tweet_pos if pos[:2] in incluided_tags]\n",
    "\n",
    "        for word in words:\n",
    "            word = word.lower().strip(\".,:;!?\\\"\\'()[]{}\")\n",
    "            if word in word_counts:\n",
    "                word_counts[word] += 1\n",
    "            else:\n",
    "                word_counts[word] = 1\n",
    "\n",
    "    # create the file if it doesn't exist\n",
    "    with open(file_path, \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"word\", \"count\"])\n",
    "        for word, count in sorted(word_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "            writer.writerow([word, count])\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {'booking': ['booking', 'booked', 'book', 'ticket', 'tickets'],\n",
    "            'canceling': ['canceled', 'cancellations'],\n",
    "            'money': ['refund', 'compensation', 'claim', 'money', 'pay', 'paid'],\n",
    "            'baggage': ['bag', 'baggage', 'luggage', 'bags'],\n",
    "            'staff': ['staff', 'crew'],\n",
    "            'waiting': ['waiting', 'delay', 'wait'],\n",
    "            'boarding': ['boarding'],\n",
    "            'stuck': ['stuck'],\n",
    "\n",
    "            'information': ['info', 'information'],\n",
    "            'customers': ['customer', 'customers', 'passenger', 'passengers'],\n",
    "            'dm': [' dm'], \n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added column baggage to tweets table\n",
      "Added column waiting to tweets table\n",
      "Added column staff to tweets table\n",
      "Added column dm to tweets table\n",
      "Added column stuck to tweets table\n",
      "Added column canceling to tweets table\n",
      "Added column booking to tweets table\n",
      "Added column customers to tweets table\n",
      "Added column money to tweets table\n",
      "Added column information to tweets table\n",
      "Added column boarding to tweets table\n"
     ]
    }
   ],
   "source": [
    "# test if the tweets table has a column for any of the categories\n",
    "category_names = set(categories.keys())\n",
    "query = \"SHOW COLUMNS FROM tweets\"\n",
    "cursor.execute(query)\n",
    "columns = cursor.fetchall()\n",
    "column_names = set([column[0] for column in columns])\n",
    "# check if there are any columns with the category names\n",
    "columns_without_categories = column_names - category_names\n",
    "if columns_without_categories != columns:\n",
    "    for category in category_names:\n",
    "        # add the column\n",
    "        query = f\"ALTER TABLE tweets ADD {category} INT(1) DEFAULT 0\"\n",
    "        cursor.execute(query)\n",
    "        \n",
    "        # get the words for the category\n",
    "        words = categories[category]\n",
    "\n",
    "        query = f\"UPDATE tweets SET {category} = 1 WHERE text REGEXP '{'|'.join(words)}'\"\n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "        print(f'Added column {category} to tweets table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbl-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
